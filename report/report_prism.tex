\documentclass[12pt]{report}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{graphicx}
\usepackage[center]{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

\begin{document}

\begin{titlepage}
\begin{center}

\hfill

\bigskip
\huge{Université de Bordeaux \par \Large Projet d'Etude et de Recherche} 
\vfill
\bigskip 
\Huge 
\bigskip Efficient, Proximity-Preserving Node Overlap Removal \par 
\vfill
\Large Claire Pennarun \par 
		Tatiana Rocher
\vfill
\Large Article by E.R. Gansner and Y. Hu (2009)	
		\bigskip 
\bigskip

\Large
\today
\end{center}
\end{titlepage}

\tableofcontents
\newpage


\begin{abstract}
The problem of removing node overlaps in a given graph layout has been well studied and various algorithms have been designed or adapted to solve it. During this project, we understood and analysed one of them, the PRISM algorithm presented by Gansner and Hu, based on a stress model, which minimize the area taken by the final layout and succeeds in retaining the global shape of the initial one. We also implemented this algorithm to be used in the Tulip framework.
\end{abstract}


\chapter{Subject presentation and state of the art}

%Partie "domaine general : graph drawing"
A graph is a data structure encoding information with the use of nodes and edges (which are binary relations between nodes).

Graph drawing aims to represent a given information as a graph, generally through a "node-link" layout, letting only nodes and edges be displayed. 

\bigskip
%Partie "domaine specifique : node overlap + etat de l'art"
Most of the layout algorithms consider nodes as points, but some need to let appear additional information as labels. For example, London subway maps would be useless without the indication of the stations on the lines.

This could lead to an overlap of some nodes. That must be avoided, as it clearly confuses the understanding of the graph.

Moreover, as we generally consider that the original layout contains significant information, an other parameter to deal with is to maintain the "global shape" of the initial representation. 

This "global shape" can be seen as "preserving the proximity relations between nodes", "preserving the orthogonal ordering of nodes"(see \cite{Mis95}) or "preserving the relative positions of nodes by limiting the vertices displacement"(see \cite{Gansner98}), and a choice between these criteria has to be made.

The easiest approach is to "scale" the layout until no overlaps occur. This method has the advantage to preserve the global shape of the layout, but the area of the graph can become very inconvenient. That is why a compromise between the preservation of the "shape of the graph" and a minimization of the total area has to be found.

Different algorithms have been devised to answer the problem, each of them focusing on a different "global shape" definition. 

\bigskip
The first approach is to try to avoid overlaps while generating the layout.

The spring-electrical model presented by Eades \cite{Eades84} and Fruchterman and Reingold \cite{FR91} considers the edges as springs between nodes, so that the spring forces move the nodes to a minimal energy state of the global system. A repelling force between non-adjacent nodes is added.
This model has been adapted by various authors (\cite{HK02}, \cite{Li05}) to take the node size into account, generally as increased repulsive forces.

The stress model of Kamada and Kawai \cite{Kamada89} is based on the assumption that a graph layout is "good" if the distance between two vertices is close to the theoretical graph distance between these vertices, i.e. to the length of their shortest path. It can also be extended to avoid as much as possible overlap along the edges.

These two models (spring-electrical model and stress model) try to avoid all overlaps, but use generally a post-processing algorithm to ensure the total overlap removal.

More details about the force-directed drawing algorithms can be found in \cite{Kob13}.

\bigskip
The second possibility is to remove overlaps after the graph is drawn : these are post-processing algorithms.

The Voronoi cluster busting algorithm \cite{Gansner98} restrains the possible displacement of a node with the use of Voronoi cells. This restriction aims to help preserving the relative positions of the nodes. In practice, the algorithm often requires a lot of iterations and the global similarity with the initial layout can be low (see for example the figure \ref{voronoi}).

\begin{figure}[h]
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.425\textwidth]{figures/size.png}}
  \fbox{\includegraphics[width=0.45\textwidth]{figures/sizeVoro.png}}
  \caption{(left) The initial layout. (right) The result of the Voronoi-based algorithm}
  \label{voronoi}
\end{figure}

The Satisfy\_VPSC algorithm \cite{VPSC06}, solving the "variable placements with separation constraints" problem, moves iteratively the nodes in the horizontal and in the vertical dimensions. This algorithm aims to minimize the vertices displacement but can generate layouts that are very dissimilar to the initial layout (see figure \ref{vpsc}).

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.6\textwidth]{figures/vpsc.png}}
  \caption{(left) The initial layout. (right) The result of the Solve\_VPSC algorithm}
  \label{vpsc}
\end{figure}

Some work on word cloud generators like Wordle (\url{http://www.wordle.net/}) allowed to develop new algorithms like Mani-Wordle \cite{Koh10} and RWordle \cite{SSSK12} based on a spiral scheme for the random placement of text labels in order to overcome overlaps.


\bigskip
%Partie : "presentation du projet"
Our project consists in understanding the algorithm PRISM proposed by Gansner and Hu in \cite{Gansner08} and in analyzing the feasability of its implementation as a plugin for the Tulip software \cite{Auber12}.

% Bien expliquer pourquoi on veut garder les relations de proximité


\chapter{PRISM algorithm}

\section{Formal notations}

We use the following notations : $G = (V,E)$ denotes the current graph, with $V$ the set of vertices (or nodes), and $E$ the set of edges. The number of vertices and of edges are denoted respectively $|V|$ (or $n$) and $|E|$.

An edge between two vertices $i$ and $j$ is denoted $(i,j)$.

The position of a node $i$ in a layout is represented as a set of 2D coordinates $p_i = (x_i, y_i)$. The initial layout position of $i$ is denoted as $p_i^0 = (x_i^0, y_i^0)$.

We consider for the PRISM algorithm that a node $i$ has a certain width $w_i$ and height $h_i$, thus forming a rectangle containing the label, likely to cause overlaps.

\section{Description of the algorithm}

The PRISM algorithm focuses on two main constraints for the final layout of the graph. First, the area taken by the layout must be minimal. The second constraint is to preserve the global "shape" of the original layout by maintaining all proximity relations between the nodes.

The PRISM algorithm runs in two main steps ; in a first step, it removes iteratively the overlaps between near nodes of the given graph $G$. Then it finds the non-near overlapping nodes and removes these overlaps as well.

\subsection{Overlap removal between near nodes}

\subsubsection{Use of a proximity graph - Delaunay Triangulation}

To find easily the overlaps between near nodes of the graph $G$, it will efficient to work on a proximity graph of $G$. Such a graph will also guarantee the preservation of the proximity relations during the different stages of the algorithm.

A \emph{proximity graph} is a graph in which two vertices are connected by an edge if (and only if) they satisfy a given geometrical property (a survey on proximity graphs can be found in \cite{JT92}).

\bigskip
The \emph{Delaunay triangulation} (DT) (named after the work of Delaunay \cite{Delaunay34}) of a graph $G$ is a triangulation of the graph such that none of the circumscribed circles of the triangles in DT(G) contains a vertex on the inside. This particular triangulation also maximises the minimum angle of the triangles found.

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.5\textwidth]{figures/DT.png}}
  \caption{(left) A graph $G$. (right) The Delaunay triangulation of $G$}
  \label{DT}
\end{figure}
%% modifier image ?

The Delaunay triangulation of $G$, as a triangulation, is also a planar graph, and has thus at most $3n -6$ edges (if $|V(G)| = n$), which is a very practical parameter for the algorithm.

\bigskip
The nearest neighbors of a vertex $v \in V(G)$ tend to form triangles with $v$ and in particular, the closest neighbor of $v$ has an edge with $v$ in DT(G), as the nearest neighbor graph of $G$ is a subgraph of DT(G) (see \cite{JT92}).

In the PRISM algorithm, we consider that the near nodes in $G$ are connected by an edge in the Delaunay triangulation of $G$.

Thus, the algorithm's first goal is to remove overlaps along the edges of the Delaunay triangulation of $G$.

\subsubsection{Ideal edge length}
The idea is to find the "ideal length" of the Delaunay triangulation edges : the "ideal length" of an edge is such that the two edge ends have no overlap.

\bigskip
In order to do that, we calculate an \emph{overlap factor} $f_{ij}$ for each edge $(i,j)$ ($i,j \in V(G)$) of the Delaunay triangulation of $G$ :

\[ f_{ij} = \max \left( \min \left(\frac{w_i/2 + w_j/2}{x_i - x_j}, 
\frac{h_i/2 + h_j/2}{y_i - y_j} \right), 1 \right) \label{of}\]

where $(x_i,y_i)$ are the coordinates of vertex $i$, $w_i$ its width and $h_i$ its height.

If two nodes $i$ and $j$ have no overlap, then $f_{ij} = 1$. 
If $i$ and $j$ do overlap, then that overlap can be removed by expanding the edge $(i,j)$ by the overlap factor found $f_{ij}$ (see figure \ref{overlapFactor}). 

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.5\textwidth]{figures/FacteurChevauchement.png}}
  \caption{Overlap factor}
  \label{overlapFactor}
\end{figure}
%% modifier image ?

Thus, the "ideal length" of an edge of the Delaunay triangulation is $l_{ij} = f_{ij}||p_i^0 - p_j^0||$, where $p_i^0$ is the initial set of coordinates of a node $i$.

We now want to find coordinates for the nodes of the initial graph such that the edges length in $DT(G)$ are close to their ideal length.

\subsubsection{Proximity stress model}

Finding this new set of coordinates means minimizing the following sum :

\[ E = \sum_{i,j \in E(DT(G))} w_{ij}(||p_i - p_j|| - l_{ij})^2\]

where $l_{ij}$ is the overlap factor and $w_{ij} = 1/(l_{ij})^2$ is a classic weighting factor, used to equalize the contributions to the total sum from the different edges.


But there are some situations where keeping $l_{ij}$ is not a good idea (see figure \ref{badcase}).

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.5\textwidth]{figures/badcase.png}}
  \caption{(right) A bad case : the big green node causes overlaps. If we attempt to remove it in one iteration only, the optimum solution will be to move the green node outside of the mesh (right), destroying the global shape of the initial layout.}
  \label{badcase}
\end{figure}
%% modifier image !

We thus want to avoid removing the "big" overlaps in one iteration only.
So we have to replace $f_{ij}$ by $\min(f_{ij},s)$, where $s > 1$ will be a limiting factor. The authors found that $s = 1.5$ worked well.

This type of sum is called a "stress function", in analogy with the well studied \emph{stress model} introduced by Kruskal in \cite{Kruskal64} and applied to graph drawing by Kamada and Kawai in \cite{Kamada89}. 
The above sum is called the \emph{proximity stress model}.

\bigskip
The minimization of the sum gives new positions for the nodes of $G$.

\subsubsection{Iteration and termination}
This first phase provides us with a new layout of the graph $G$, in which the nodes positions are given according to the previous minimization of the proximity stress model.

This layout may still contain overlaps. We must thus iterate the construction of the Delaunay triangulation, the computation of the overlap factors, the minimization of the proximity stress model and the move of the nodes until no more overlaps occur along the edges of the Delaunay triangulation of the graph.

\bigskip
The process of the first stage makes clear that no overlaps can appear : the distance between nodes can only be increasing and the proximity graph on which we are calculating, as a triangulation, is a rigid graph.

But the authors do not explain formally the reason of the termination of this phase : the stress function could always be smaller but never reach a local minimum. Moreover, the number of iterations needed during the first phase is not explicited nor bounded in the article.

The authors' implementation of PRISM contains a threshold : if the gain in the minimization of the stress function is smaller, the first phase of the algorithm ends.

%% A preciser et detailler

\subsection{Overlap removal between non-near nodes}

The first step removes the overlap between ends of edges of the Delaunay triangulation of the graph. But some overlaps can be caused by nodes not being near, and thus not generating an edge in the proximity graph. These overlaps can not have been removed by the first stage of the PRISM algorithm.

To find these still overlapping nodes, we have to use a scan-line algorithm.

\subsubsection{Scan-line algorithm}

A scan-line algorithm is an algorithm which will consider all the points of a layout.

We can not use a algorithm which uses the graph properties because the vertices do not know the positions of others vertices, so we can not find the overlaps by using the vertices properties.

For all the ordinate's points we consider all the points in the abscissa. If there is an overlap at a point, we add the edge (between the two vertices overlapping) in the Delaunay triangulation. 
% à etoffer


\bigskip
It is interesting to note that one of the opponent algorithms, Satisfy\_VPSC \cite{VPSC06}, mainly uses a scan-line algorithm to remove overlaps.

\subsubsection{Overlap removal}

The second stage uses the same processus as the first one, only adding the overlapping edges found by the scan-line algorithm to the Delaunay triangulation before the calculation of the overlap factors and the resolution of the proximity stress model.

This stage ends when no more overlaps are found by the scan-line algorithm.
% A completer ?

\begin{figure}
\begin{algorithm}[H]
\caption{PRISM}
\KwIn{$p_i^0$ : coordinates of each vertex  \\
	 width $w_i$ and height $h_i$ of each vertex ($i = 1,2,...,|V|$)}
	 
\Repeat{}{$G_{DT}$ : proximity graph of $G$ by Delaunay triangulation \\
	\For{all edges of $G_{DT}$}
	{Compute the overlap factor}
	$\{p_i\}$ : solution of the proximity stress model
	
	$p_i^0 = p_i$
}	
(no more overlaps along edges of $G_{DT}$)
\BlankLine
\Repeat{}{$G_{DT}$ : proximity graph of $G$ by Delaunay triangulation \\
	Find overlaps in $G$ through a scan-line algorithm \\
	Add the overlapping edges to $G_{DT}$ \\
	\For{all edges of $G_{DT}$}
	{Compute the overlap factor}
	$\{p_i\}$ : solution of the proximity stress model
	
	$p_i^0 = p_i$
}	
(no more overlaps found by the scan-line algorithm)
\end{algorithm}
\caption{The PRISM algorithm}
\end{figure}

\subsection{Dissimilarity metrics}

To be able to compare different graph layouts, the authors propose three dissimilarity metrics : the area taken by the layout, a metric based on the edge length ratio in the proximity graphs of the initial and final layouts, and a metric measuring the vertices displacement between the initial and the final layouts.

\subsubsection{Area}
As said before, it is easy to remove all the overlaps by extending all the edges of the initial layout. But the final layout can be extremely large and thus unreadable, so we want to keep an area as small as possible.

\subsubsection{Edge length ratio}
We first calculate the ratio between the edge lengths of the proximity graphs of the original layout and the final one. The metric is then defined as the normalized standard deviation to the mean ratio found.

This metric has to be as small as possible to minimize the changes made to the edges length during the algorithm.

The edge length ratio has to be calculated on a rigid graph (as the Delaunay triangulations) to be meaningful : two layouts of the same graph can be completely different if the graph is not rigid (see figure \ref{rigidGraph}).

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.5\textwidth]{figures/rigidGraph.png}}
  \caption{Two different graphs having the same edge length ratio. As they are not rigid, the layouts are clearly different.}
  \label{rigidGraph}
\end{figure}

\subsubsection{Vertices displacement}

The third measure of dissimilarity is the calculation of the displacement of vertices $\sigma_{disp}$ between the original layout and the final one. We consider that layouts resulting from a scaling, a shift or a rotation are identical. 

Thus, computing the displacement of vertices means finding the optimal scaling, shift and rotation minimizing the displacement:

\[\sigma_{disp}(p^0, p) = \min_{t \in \mathbb{R}^2, \rho, s \in \mathbb{R}} 
\sum_{i \in V(G)} || s R p_i + t - p_i^0||^2 \]

where $R = \begin{pmatrix} \cos(\rho) & \sin(\rho) \\ -\sin(\rho) & \cos(\rho) \end{pmatrix}$ is the rotation matrix, $\rho$ the rotation, $s$ is the scaling, $t$ the translation, $p_i$ is the position of the node $i$ in the final layout and $p_i^0$ is the position of $i$ in the initial layout

\section{Complexity}

We will here present the estimated complexity of the PRISM algorithm. This estimation has been made by the authors, which have been presenting in as an "exact" estimation, taking for example the number of iterations in account.

The computation of the Delaunay triangulation of a given graph can be made in $O(|V| \log |V|)$ time.

The calculation of the overlap factors (see \ref{of}) is made in $O(1)$ time for each factor. Since the Delaunay triangulation is planar and thus has at most $3|V| -6$ edges, this step requires a $O(|v|)$ time in total.

The resolution of the proximity stress model can be implemented in various ways, which influences the computational complexity. The authors chose to implement it using a stress majorization technique \cite{Gansner05}, which itself uses a conjugate gradient algorithm. This resolution takes $O(m*k*|V|)$ time, where $m$ is the average number of stress majorization iterations and $k$ is the average number of iterations for the conjugate gradient algorithm. The authors chose to set $m =1$, claiming that the proximity stress model did not need to be accurately solved in each iteration.

The scan-line algorithm can be implemented in $O(l |V| (\log |V| + l))$ time \cite{VPSC06}, where $l$ is the number of still existing overlaps. The authors claim that $l$ is usually a small number and consider that this step is taking time $O(|V| (\log |V|))$. We did not succeed in checking this assumption.

Overall, the PRISM algorithm takes $O(t(|V| \log |V| + k|V|))$ time, where $t$ is the total number of iterations of the two \texttt{while} loops. This number $t$ is quite difficult to bound, since it depends on the technique used to solve the proximity stress model, the number of nodes and their positions. The authors chose not to try to bound it but to keep it in the computational complexity.

\chapter{Implementation within Tulip}

Our goal was to implement the PRISM algorithm within Tulip, as a basis which could be reused and improved later. We had some problems to implement the given algorithm as the authors had done within the GraphViz \cite{Gansner02} software, but we did find solutions.

\section{The Tulip framework}

The Tulip framework \cite{Auber12}, developed mainly by the Data Visualization team of the LaBRI (Bordeaux), is a data visualization software dedicated to the analysis and visualization of relational data. It focuses on the manipulation of graphs. Our goal was to implement the PRISM algorithm as a plugin for Tulip, reusing some of the tools already present in the software, such as the calculation of the Delaunay triangulation of a graph.

Tulip uses particular structures to deal with graph manipulations, and one of these structure is very important for the PRISM algorithm : the \texttt{node} structure.

The PRISM algorithm considers that the label is part of the node, and that the size of the node is determined by the size of the underlying label.

But in Tulip, the labels are seen as a "property" of the graph, and are decorrelated from the nodes themselves. They generally are dynamic sized, and displayed in order to avoid overlaps. We thus do not have access to the size of labels.

The solution was to increase the size of the nodes and to force the labels inside them (see figure \ref{graphTulip}). Thus, we could considerate that the "labels" were overlapping, even if it was artificially.

\begin{figure}[h]
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.46\textwidth]{figures/graphTulip0.png}}
  \fbox{\includegraphics[width=0.6\textwidth]{figures/graphTulipWithLabels0.png}}
  \caption{Adjustment of the nodes size in Tulip}
  \label{graphTulip}
\end{figure}

\section{Resolution of the stress model}

The resolution of the proximity stress model can be done in many different ways. The authors, through their implementation in GraphViz \cite{Gansner02}, a set of graph drawing tools, chose to solve it via a stress majorization technique (described in details in \cite{Gansner05}). 

\subsection{Stress majorization}

We first considered to implement the resolution of the proximity stress model in the same way as the authors by employing a stress majorization technique.

This procedure consists in bounding the function we want to optimize by a series of quadratic functions from above. Solving the stress model means then finding an optimum, which is done by solving a series of linear systems.

\bigskip
This resolution implies the manipulation of weighted Laplacian of matrices and the use of a conjugate gradient algorithm with preconditions. These features are not present in the Tulip framework and were too complex to implement in the given time for the project. 

\bigskip
Another possibility was to retrieve some implementation from the GraphViz suite and use it as an external plugin or module. 
But an analysis of the dependencies of the requested function (the \texttt{StressMajorizationSmoother\_smooth()} function in the \texttt{post\_process.c} file) were to important to do so.

We used a python script to retrieve the number of lines of the dependance files of \texttt{post\_process.c}. The script is given as an annex (mettre ref). We used the \texttt{-MM} option of \texttt{gcc} to generate the headers (.h files) necessary to the execution of the file, then searched for the .c files having the same name and count the number of lines. As a result, 16 of the 52 needed headers have a corresponding .c having the same name, and these 16 files have a total of 14033 lines.
This was considered as a too large amount of code to use as an external plugin or module (and these are only the first level dependancies !).

\bigskip
We then focused on finding an other resolution method for the proximity stress model and we decided to adapt an algorithm based on a Newton-Raphson method.

\subsection{Kamada \& Kawai - Newton-Raphson method}

Kamada and Kawai \cite{Kamada89} proposed an algorithm computing a local minimum of the energy $E$ of a system. We adapted and implemented it by using 
\[ E = \sum_{i,j \in E(DT(G))} w_{ij}(||p_i - p_j|| - l_{ij})^2 \]
The purpose is to calculate new positions $p_i = (x_i, y_i)$ for $i = 1... n$, locally minimizing the global stress function $E$. 

We thus want to find $x_i, y_i$ such that $\delta E / \delta x_i = \delta E / \delta y_i = 0$ for $i = 1... n$. That means solving simultaneously $2n$ (non-linear) equations.

\bigskip
The Kamada and Kawai algorithm consists in moving only one node $i$ at a time to reach $\delta E / \delta x_i = \delta E / \delta y_i = 0$, "freezing" the other nodes during the computation.

We adapted the computation of $\delta E / \delta x_i$ and $\delta E / \delta y_i$ to our configuration : we considered the following values :

\begin{eqnarray*}
\frac{\delta^2 E}{\delta x_i}  & = & \sum_{(i,m) \in E(DT)} w_{im} ( (x_m - x_i) - \frac{l_{im} (x_m - x_i)}{||p_m - p_i||} \\
\frac{\delta^2 E}{\delta y_i}  & = & \sum_{(i,m) \in E(DT)} w_{im} ( (y_m - y_i) - \frac{l_{im} (y_m - y_i)}{||p_m - p_i||}
\end{eqnarray*}
 
where $DT$ is the Delaunay triangulation of the graph, $l_{im}$ is the ideal length of the $(i,m)$ edge, $w_{im} = 1/(l_{im})^2 $ is a weighting factor, and $||p_m - p_i||$ is the euclidian distance between the nodes $m$ and $i$.

At each iteration, the node moved is the one having the largest value of $\Delta_i$ (i.e. the "further" one of the condition to reach):

\[\Delta_i = \sqrt{\left(\frac{\delta E}{\delta x_i}\right)^2 + \left(\frac{\delta E}{\delta y_i}\right)^2} \]

\bigskip
We thus only have to solve a two-equations system at each step, the two unknown values being $\delta x$ and $\delta y$. The system is found by the use of the Newton-Raphson method :
\begin{eqnarray}
\label{eq1}
\frac{\delta^2 E}{\delta x_i^2}(p_i) \times \delta x +  \frac{\delta^2 E}{\delta x_i \delta y_i}(p_i) \times \delta y  & = & - \frac{\delta E}{\delta x_i} (p_i) \\
\frac{\delta^2 E}{\delta y_i \delta x_i}(p_i) \times \delta x +  \frac{\delta^2 E}{\delta y_i^2}(p_i) \times \delta y & = & - \frac{\delta E}{\delta y_i} (p_i)
\label{eq2}
\end{eqnarray}

The $(\delta x, \delta y)$ found are added to the current position of the node $i$, and this is done iteratively until $\Delta_i < \varepsilon$, where $\varepsilon$ is a threshold determined by the user.

The algorithm stops when all considered nodes have reached $\Delta_i < \varepsilon$. As $\varepsilon \neq 0$, it happens that all nodes have not been removed.

\begin{figure}
\begin{algorithm}[H]
\caption{Kamada-like algorithm}
\For {all edges $(i,j)$ of the Delaunay triangulation}
{Compute $l_{ij}$}

\For {all nodes $i$ of the graph}
{Compute $\delta E / \delta x_i$, $\delta E / \delta y_i$ and $Delta_i$}

\While{($\Delta_m = \max_i(\Delta_i)) > \varepsilon$}{
	\While{$\Delta_m > \varepsilon$}
	{
	$(\delta x, \delta y)$ = solutions of the \ref{eq1} and \ref{eq2} equations
	
	$x_m += \delta x$
	
	$y_m += \delta y$
	
	Compute $\Delta_m$
	}
}

\end{algorithm}
\caption{A Kamada-like algorithm to solve the proximity stress model}
\label{algkamada}
\end{figure}

\subsubsection{Resolution of the equations}

The resolution of the \ref{eq1} and \ref{eq2} equations has been implemented specifically: the solutions of a system of equations such as 
$\begin{cases}
Ax + By = E \\
C x + Dy = F
\end{cases}$
are : $x = \frac{ED - BF}{AD - BC}$ and $y = \frac{1}{D} \times(F - \frac{CED - BCF}{AD- BC})$.

This basic implementation aims to decrease the total computational time, as this resolution is done multiple times.

\subsubsection{Complexity}

The computation of $l_{ij}$ for each edge $(i,j)$ of the Delaunay triangulation can be done in $O(n)$ time, as the Delaunay triangulation of a graph $G$ is a planar graph and has at most $3n -6$ edges (if $|V(G)| = n$).

The calculation of  $\delta E / \delta x_i$, $\delta E / \delta y_i$ and $Delta_i$ for all nodes $i$ of the graph requires a traversal of all neighbors of $i$ in the Delaunay triangulation. The number of neighbors is bounded by $n$. This calculation can thus done in a $O(n^2)$ time.

The pre-computation is thus done in a $O(n^2)$ time.

Finding the maximum of $\Delta_i$ requires $O(n)$ time. This could maybe be improved by sorting the $\Delta_i$ structure at its computation. The update of $\Delta_m$ at the end of the loop can be done in $O(1)$ as the preceding value of $p_m = (x_m, y_m)$ is memorized. The outer loop thus requires $O(n)$ time for each iteration.

The calculation of the \ref{eq1} and \ref{eq2} equations factors is done via a traversal of all neighbors of $m$ in the Delaunay triangulation, and thus requires a $O(n^2)$ time.
The solutions of these equations is computed in $O(1)$, as the implementation is made expressively for them.

In the end, the time needed to end the two \texttt{while} loops is $O(n) \times T O(n^2)$, where $T$ is the number of iterations of the inner loop. $T$ is quite difficult to bound, since it is dependant of the number of nodes and their initial position.

\section{Finding the remaining overlaps}
As we want to find the remaining overlaps, a scan-line algorithm has generally to consider all the points of the graph layout. But we found a implemented class in Tulip, \texttt{BoundingBox}, which helped us to implement a good non-naive algorithm. 

\bigskip
In Tulip, each bounding box is represented by two points : the lowest and leftest point and the highest and rightest point of the bounding box.

We encompass each node in a BoundingBox so we can use its properties : instead of iterating over all the points of the image, we only use the lowest and the highest points of each BoundingBox. 

\bigskip
In a first step, we sort the BoundingBox by their lowest point in the abscissa. Thus, if the BoundingBox $b1$ is placed before the BoundingBox $b2$ in the sorted list, and if the highest point of $b1$ is higher than the lowest point of $b2$, that means that there may be an overlap in the graph between $b1$ and $b2$. 

In the contrary, if the highest point of $b1$ is lower than the lowest point of $b2$, all the BoundingBox sorted after $b1$ can not cause an overlap with $b1$.

\bigskip
This algorithm returns the edges of the overlaps, which we will add in the Delaunay triangulation.

\begin{figure}
\begin{algorithm}[H]
\caption{Finding remaining overlaps}
\KwIn{list of BoundingBox}
Initialize a listOfBoxes

Sort the boxes by their lower point

\For{all boxes from 0 to length-2}
	{\While{there is a overlap with the next box in the list}{
		\If{there is a real overlap in the graph}
			{add the edge between this boxes in the listOfBoxes}
		box = next box}}
\KwRet{listOfBoxes}
\end{algorithm}
\caption{Algorithm for finding overlaps with bounding boxes}
\label{algscanline}
\end{figure}

\begin{figure}[h]
  \center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.5\textwidth]{figures/BoundingBoxes.png}}
  \caption{(Red) the graph with the bounding boxes. (Green) the sorted list of BoundingBox}
  \label{scanline}
\end{figure}

In the figure \ref{scanline} we show an exemple of our algorithm \ref{algscanline}. We have colored the graph in red and the list of bounding boxes sorted by abscissa in green. 

We can see a lot of overlaps in the green part. The boxes $b'2$ and $b'3$ do overlap in the abscissa and in the graph. But the boxes $b'1$ and $b'2$ overlap in the abscissa and don't overlap in the graph, this is resolved by the line 5 of the algorithm by a check in the graph (we use the method \texttt{BoundingBox.contains(BoundingBox)}).

Moreover, the boxes $b'1$ and $b'3$ do not overlap in the abscissa, so none of the boxes higher that $b3$ could overlap with $b1$.

\subsubsection{Complexity}

As this algorithm is mainly based on the traversal of the BoundingBox list, its complexity is in $O(n^2)$, where $n$ is the number of nodes in the layout (and thus, the number of bounding boxes in the list). 

\section{Tests and results}
We conducted some tests on our algorithm. 

A first phase was to apprehend the effect of variation of the $\varepsilon$ parameter in the resolution of the stress model.
The tests have been run on the \texttt{b124} graph, which has 79 nodes and 281 edges. We variated the value of $\varepsilon$ from 0.0005 to 0.0000001. We also noted the number of overlaps found before and after the two main loops, and the proportion of the area taken by the final layout on the area taken by the initial one.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
	\hline 
	 $\varepsilon$ & tps(s) & initial & after 1st phase & before 2nd phase & end & area \\
	\hline
	0.0005 & 7.2 & 102 & 78 & 202 & 169 & 1.7\\
	0.0001 & 17.7 & 102 & 38  & 134 & 126 & 2.07\\
	0.00005 & 25.7 & 102 & 24 & 109 & 118 & 2.07\\
	0.00001 & 38.9 & 102 & 29 & 123 & 100 & 2.08\\
	0.000005 & 52.9 & 102 & 27 & 111 & 87 & 2.34\\
	0.000001 & 138 & 102 & 16 & 88 & 74 & 2.22\\
	\hline
\end{tabular}
\end{center}

\bigskip
We see that the lower is the value of $\varepsilon$, the more the number of overlaps removed in the first phase increases. The ratio "final area"/"initial area" is also increasing with the diminution of $\varepsilon$.

Our algorithm on \texttt{b124} with $\varepsilon < 0.00005$ gives final layouts where overlaps are difficult to see, and we consider that a $0.00001$ is a good average value for $\varepsilon$, giving a good visual result and not taking too much time and final area.

\bigskip
It is important to note that since the first phase does not remove all the overlaps, the overlaps still present along the edges of the Delaunay triangulation will be "double-counted" by the algorithm finding the remaining overlaps via the bounding boxes. 

\begin{figure}[h]
	\center
  \setlength\fboxsep{5pt}
  \setlength\fboxrule{0.5pt}
  \fbox{\includegraphics[width=0.6\textwidth]{figures/b124a.png}}
  
  \fbox{\includegraphics[width=0.7\textwidth]{figures/b124b.png}}
  
  \fbox{\includegraphics[width=0.7\textwidth]{figures/b124c.png}}
  
  \caption{(up) The initial \texttt{b124} graph \\ (middle) after the first phase of our algorithm \\ (down) after the second phase ($\varepsilon = 0.0001$)}
  \label{b124}
\end{figure}



\chapter{Conclusion}

Since PRISM :

ePRISM : PRISM on overlap of edges \cite{Hu09}

\appendix
\chapter{Python script to find the dependancies of the \texttt{post\_process.c} file in GraphViz}

\begin{verbatim}
#! bin/python
import os
import os.path
s = os.popen("gcc -MM post_process.c -I ../common/ -I ../gvc/ -I 
../pathplan/ -I ../cdt/ -I ../sparse/ -I ../neatogen/ -I ../sfdpgen/ 
-I ../cgraph/").read()
s = s.split(' ',2)[2]
s = s.replace(".h",".c")
totalLineAmount = 0
nbNotFoundFiles = 0
nbFoundFiles = 0
for f in s.split(' '):
    if os.path.isfile(f):
        cm = os.popen("wc -l " + f).read()
        cm = cm.split(' ')[0]
        totalLineAmount += int(cm)
	nbFoundFiles += 1
    else:
        nbNotFoundFiles += 1
print s, totalLineAmount, nbNotFoundFiles, nbFoundFiles
\end{verbatim}

\bibliographystyle{plain}
\bibliography{report_prism}


\end{document}
